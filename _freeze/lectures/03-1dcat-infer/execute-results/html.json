{
  "hash": "cc646d1f345904d92e60df387ca6f99c",
  "result": {
    "markdown": "---\ntitle: \"Statistical Inference for 1D Categorical Data\"\nauthor: \"Prof Ron Yurko\"\nfooter:  \"[statds-36315-spring25](https://ryurko.github.io/statds-36315-spring25/)\"\ndate: 2025-01-22\nengine: knitr\nformat:\n  revealjs:\n    theme: theme.scss\n    chalkboard: true\n    pdf-separate-fragments: true\n    slide-number: c/t\n    smaller: true\n    code-line-numbers: true\n    linestretch: 1.25\n    html-math-method:\n      method: mathjax\n      url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\n---\n\n\n\n\n## Announcements, previously, and today...\n\n::: {style=\"font-size: 80%;\"}\n\n+ **HW1 is posted and due Wednesday Jan 29** \n\n+ **You have Lab 2 again on Friday**\n\nOffice hours schedule:\n\n+ My office hours (BH 132D): Wednesdays and Thursdays @ 2 PM\n\n+ Anna (zoom): Mondays @ 2 PM\n\n+ Perry (zoom): Wednesdays @ 11 AM\n\n:::\n\n. . .\n\n::: {style=\"font-size: 80%;\"}\n\n\n+ Discussed 1D categorical data, basic summaries with counts and proportions\n\n+ Introduced different area plots for visualizing 1D categorical data\n\n+ **We make bar charts for categorical data** (I told you repeatedly that pie charts suck)\n\n:::\n\n. . .\n\n::: {style=\"font-size: 80%;\"}\n\n**TODAY: quantify and display uncertainty for 1D categorical data**\n\n+ Add confidence intervals to bar charts\n\n+ Review the Chi-Squared Test\n\n+ Discuss connections between visualizations and statistical significance\n\n:::\n\n---\n\n## Crimes against bar charts\n\n![](https://venngage-wordpress.s3.amazonaws.com/uploads/2021/01/womenicons.jpg){fig-align=\"center\"width=45%}\n\n---\n\n## Crimes against bar charts\n\n![](https://pbs.twimg.com/media/Ee6WX52WsAAP9wT.png){fig-align=\"center\"width=45%}\n\n---\n\n## What does a bar chart show?\n\n**Marginal Distribution**\n\n+ Assume categorical variable $X$ has $K$ categories: $C_1, \\dots, C_K$\n\n+ **True** marginal distribution of $X$: \n\n$$\nP(X = C_j) = p_j,\\ j \\in \\{ 1, \\dots, K \\}\n$$\n\n. . .\n\n**We have access to the Empirical Marginal Distribution**\n\n+ Observed distribution of $X$, our best estimate (MLE) of the marginal distribution of $X$: $\\hat{p}_1$, $\\hat{p}_2$, $\\dots$, $\\hat{p}_K$\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(penguins$species) / nrow(penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   Adelie Chinstrap    Gentoo \n0.4418605 0.1976744 0.3604651 \n```\n:::\n:::\n\n\n\n---\n\n## Bar charts with proportions\n\n+ [`after_stat()`](https://ggplot2.tidyverse.org/reference/aes_eval.html) indicates the aesthetic mapping is performed after statistical transformation\n\n+ Use `after_stat(count)` to access the `stat_count()` called by `geom_bar()`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"3\"}\npenguins |>\n  ggplot(aes(x = species)) +\n  geom_bar(aes(y = after_stat(count) / sum(after_stat(count)))) + \n  labs(y = \"Proportion\")\n```\n\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n---\n\n## Compute and display the proportions directly\n\n+ Use `group_by()`, `summarize()`, and `mutate()` in a pipeline to compute then display the proportions directly\n\n+ Need to indicate we are displaying the `y` axis as given, i.e., the identity function\n\n\n\n::: {.cell layout-align=\"center\" output-location='slide'}\n\n```{.r .cell-code  code-line-numbers=\"2-5,7\"}\npenguins |>\n  group_by(species) |> \n  summarize(count = n(), .groups = \"drop\") |> \n  mutate(total = sum(count), \n         prop = count / total) |> \n  ggplot(aes(x = species)) +\n  geom_bar(aes(y = prop), stat = \"identity\") \n```\n\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n---\n\n## What about uncertainty?\n\n+ Quantify uncertainty for our estimate $\\hat{p}_j = \\frac{n_j}{n}$ with the **standard error**:\n\n$$\nSE(\\hat{p}_j) = \\sqrt{\\frac{\\hat{p}_j(1 - \\hat{p}_j)}{n}}\n$$\n\n. . .\n\n+ Compute $\\alpha$-level __confidence interval__ (CI) as $\\hat{p}_j \\pm z_{1 - \\alpha / 2} \\cdot SE(\\hat{p}_j)$\n\n+ Good rule-of-thumb: construct 95% CI using $\\hat{p}_j \\pm 2 \\cdot SE(\\hat{p}_j)$\n\n+ Approximation justified by CLT, so CI could include values outside of [0,1]\n\n\n\n---\n\n## Add standard errors to bars\n\n+ Need to remember each CI is for each $\\hat{p}_j$ marginally, **not** jointly\n\n+ Have to be careful with __multiple testing__ \n\n\n\n::: {.cell layout-align=\"center\" output-location='slide'}\n\n```{.r .cell-code  code-line-numbers=\"6-8,11-12\"}\npenguins |>\n  group_by(species) |> \n  summarize(count = n(), .groups = \"drop\") |> \n  mutate(total = sum(count), \n         prop = count / total,\n         se = sqrt(prop * (1 - prop) / total), \n         lower = prop - 2 * se, \n         upper = prop + 2 * se) |> \n  ggplot(aes(x = species)) +\n  geom_bar(aes(y = prop), stat = \"identity\") +\n  geom_errorbar(aes(ymin = lower, ymax = upper), \n                color = \"red\") \n```\n\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n---\n\n##  Useful to order categories by frequency with [`forcats`](https://forcats.tidyverse.org/)\n\n\n\n::: {.cell layout-align=\"center\" output-location='slide'}\n\n```{.r .cell-code  code-line-numbers=\"9\"}\npenguins |>\n  group_by(species) |> \n  summarize(count = n(), .groups = \"drop\") |> \n  mutate(total = sum(count), \n         prop = count / total,\n         se = sqrt(prop * (1 - prop) / total), \n         lower = prop - 2 * se, \n         upper = prop + 2 * se,\n         species = fct_reorder(species, prop)) |>\n  ggplot(aes(x = species)) +\n  geom_bar(aes(y = prop), stat = \"identity\") +\n  geom_errorbar(aes(ymin = lower, ymax = upper), \n                color = \"red\") \n```\n\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n---\n\n## [Don't do this...](https://retractionwatch.com/2022/12/05/a-paper-used-capital-ts-instead-of-error-bars-but-wait-theres-more/)\n\n\n![](https://retractionwatch.com/wp-content/uploads/2022/12/3802603.fig_.009-768x512.png){fig-align=\"center\"width=45%}\n\n\n---\n\n## Chi-squared test for 1D categorical data:\n\n::: {style=\"font-size: 75%;\"}\n\n+ __Null hypothesis__ $H_0$: $p_1 = p_2 = \\dots = p_K$, compute the test statistic:\n\n$$\n\\chi^2 = \\sum_{j=1}^K \\frac{(O_j - E_j)^2}{E_j}\n$$\n\n+ $O_j$: observed counts in category $j$\n\n+ $E_j$: expected counts under $H_0$, i.e., each category is equally to occur $n / K = p_1 = p_2 = \\dots = p_K$\n\n:::\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchisq.test(table(penguins$species))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tChi-squared test for given probabilities\n\ndata:  table(penguins$species)\nX-squared = 31.907, df = 2, p-value = 1.179e-07\n```\n:::\n:::\n\n\n\n<!-- - Large $\\chi^2 \\rightarrow$ observed counts are very different from expected counts -->\n\n<!-- - Therefore we should just reject the null hypothesis -->\n\n<!-- - i.e., the $p$-value is small because we would not expect to see observed counts so extreme if the null were true -->\n\n<!-- - But if we reject, cannot tell _which_ probabilities are different... -->\n\n<!-- - _Can we use graphs to tell us which are different...?_ -->\n\n---\n\n## Hypothesis testing review\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {style=\"font-size: 85%;\"}\n\nComputing $p$-values works like this:\n\n- Choose a test statistic.\n\n- Compute the test statistic in your dataset.\n\n- Is test statistic \"unusual\" compared to what I would expect under $H_0$?\n\n- Compare $p$-value to __target error rate__ $\\alpha$ (typically referred to as target level $\\alpha$ )\n\n- Typically choose $\\alpha = 0.05$ \n\n  - i.e., if we reject null  hypothesis at $\\alpha = 0.05$ then, assuming $H_0$ is true, there is a 5% chance it is a false positive (aka Type 1 error)\n  \n\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.fragment}\n\n![](https://measuringu.com/wp-content/uploads/2021/04/042121-F2.jpg){fig-align=\"center\"}\n\n:::\n\n:::\n\n::::\n\n\n---\n\n## Chi-squared test for 1D categorical data:\n\n::: {style=\"font-size: 75%;\"}\n\n+ __Null hypothesis__ $H_0$: $p_1 = p_2 = \\dots = p_K$, compute the test statistic:\n\n$$\n\\chi^2 = \\sum_{j=1}^K \\frac{(O_j - E_j)^2}{E_j}\n$$\n\n+ $O_j$: observed counts in category $j$\n\n+ $E_j$: expected counts under $H_0$, i.e., each category is equally to occur $n / K = p_1 = p_2 = \\dots = p_K$\n\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchisq.test(table(penguins$species))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tChi-squared test for given probabilities\n\ndata:  table(penguins$species)\nX-squared = 31.907, df = 2, p-value = 1.179e-07\n```\n:::\n:::\n\n\n\n---\n\n## Graphics versus Statistical Inference\n\n- Reminder Anscombe's Quartet: where statistical inference was the same but the graphics were very different\n\n![](https://upload.wikimedia.org/wikipedia/commons/e/ec/Anscombe%27s_quartet_3.svg){fig-align=\"center\"width=55%}\n\n- __The opposite can be true!__ Graphics are the same, but statistical inference is very different...\n\n\n---\n\n## Example: 3 categories, $p_1 = 1/2,\\ p_2 = p_3 = 1/4$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n---\n\n## Example: 3 categories, $p_1 = 1/2,\\ p_2 = p_3 = 1/4$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n---\n\n## Example: 3 categories, $p_1 = 1/2,\\ p_2 = p_3 = 1/4$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n---\n\n## Example: 3 categories, $p_1 = 1/2,\\ p_2 = p_3 = 1/4$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n---\n\n## Power under this scenario: (2n/4, n/4, n/4)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n---\n\n## How do we combine graphs with inference?\n\n\n1. Simply add $p$-values (or other info) to graph via text\n\n2. Add confidence intervals to the graph\n\n  - Need to remember what each CI is for! \n  \n  - Our CIs on previous slides are for each $\\hat{p}_j$ marginally, __NOT__ jointly\n\n  - Have to be careful with __multiple testing__...\n\n---\n\n## CIs will visually capture uncertainty in estimates\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-14-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n:::\n\n::::\n\n---\n\n## (Rough) Rules-of-thumb for comparing CIs on bar charts\n\n::: {style=\"font-size: 75%;\"}\n\n- Comparing overlap of two CIs is __NOT__ exactly the same as directly testing for a significant difference...\n\n  - Really you want CI( $\\hat{p}_1 - \\hat{p}_2$ ), not CI( $\\hat{p_1}$ ) and CI( $\\hat{p_2}$ )\n  \n  - CI( $\\hat{p_1}$ ) and CI( $\\hat{p_2}$ ) not overlapping implies $0 \\notin$ CI( $\\hat{p}_1 - \\hat{p}_2$ )\n\n  - _However_ CI( $\\hat{p_1}$ ) and CI( $\\hat{p_2}$ ) overlapping __DOES NOT__ imply $0 \\in$ CI( $\\hat{p}_1 - \\hat{p}_2$ ) \n\n\nRoughly speaking:\n\n  - If CIs don't overlap $\\rightarrow$ significant difference\n  \n  - If CIs overlap a little $\\rightarrow$ ambiguous\n  \n  - If CIs overlap a lot $\\rightarrow$ no significant difference\n  \n:::\n  \n. . .\n\n::: {style=\"font-size: 75%;\"}\n\nBut if we're comparing more than two CIs simultaneously, we need to account for __multiple testing__!\n\n  - When you look for all non-overlapping CIs: implicitly making $\\binom{K}{2} = \\frac{K!}{2!(K-2)!}$ pairwise tests in your head!\n  \n:::\n\n---\n\n## Corrections for multiple testing\n\n::: {style=\"font-size: 75%;\"}\n\n- In those bar plots, when we determine whether CIs overlap we make 3 comparisons:\n\n  1. A vs B\n  \n  2. A vs C\n  \n  3. B vs C\n  \n**This is a multiple testing issue**\n\n:::\n\n. . .\n\n::: {style=\"font-size: 75%;\"}\n\n- In short: we will make Type 1 errors (chance of false rejecting) more than 5% of the time!\n\n- Reminder: Type 1 error = Rejecting $H_0$ when $H_0$ is true\n\n- e.g., CIs don't overlap but actually $H_0: p_A = p_B$ is true\n  \n- If only interested in A vs B __and nothing else__, then just construct 95% CI for A vs B and _control error rate_ at 5%\n  \n- However, if we construct several CIs, where A vs B is just one comparison we make, our Type 1 error rate > 5%!\n\n:::\n\n---\n\n## Corrections for multiple testing\n\n::: {style=\"font-size: 75%;\"}\n\nVast literature on corrections for multiple testing (beyond the scope of this class... but in my thesis!)\n\nBut you should understand the following:\n\n1. Corrections for multiple testing inflate $p$-values (i.e., make them bigger)\n\n2. Equivalently, they inflate CIs (i.e., make them wider)\n\n3. Purpose of these corrections is to control Type 1 error rate $\\leq 5\\%$\n\n:::\n\n. . .\n\n::: {style=\"font-size: 75%;\"}\n\nWe'll focus on the __Bonferroni correction__, which inflates $p$-values the most but is easy to implement and very popular:\n\n+ We usually reject null hypothesis when $p$-value $\\leq .05$\n\n+ __Bonferroni__: if making $K$ comparisons, reject only if $p$-value $\\leq .05/K$\n\n+ For CIs: instead of plotting 95% CIs, we plot (1 - $0.05/K$)% CIs\n\n  + e.g., for $K = 3$ then plot 98.3% CIs\n  \n:::\n  \n---\n\n## Impact of Bonferroni correction on CIs...\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-16-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-1dcat-infer_files/figure-revealjs/unnamed-chunk-17-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n:::\n\n::::\n\n---\n\n## Recap and next steps\n\n::: {style=\"font-size: 80%;\"}\n\n+ Bar charts display the empirical distribution of the categorical variable ( $\\hat{p}_1, \\dots, \\hat{p}_K$ )\n\n+ Chi-squared test is a _global test_ for 1D categorical data, testing $H_0 : p_1 = \\cdot \\cdot \\cdot = p_K$\n\n  + Does not tell us which probabilities differ! \n\n+ Can visualize CIs for each $\\hat{p}_1$, $\\dots$, $\\hat{p}_K$, but need to deal with multiple testing\n  \n+ Graphs with the same trends can display very different statistical significance (largely due to sample size)\n\n:::\n\n. . .\n\n::: {style=\"font-size: 80%;\"}\n\n+ **HW1 is due next week and you have Lab 2 on Friday!**\n\n+ **Next time**: 2D categorical data\n\n+ Recommended reading: \n\n  + [CW Chapter 16.2 Visualizing the uncertainty of point estimates](https://clauswilke.com/dataviz/visualizing-uncertainty.html#visualizing-the-uncertainty-of-point-estimates)\n\n:::\n\n",
    "supporting": [
      "03-1dcat-infer_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}