{
  "hash": "055d1e0a4dba67b0fa075336744eceab",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Comparing Distributions and Statistical Power\"\nauthor: \"Prof Ron Yurko\"\nfooter:  \"[statds-36315-spring25](https://ryurko.github.io/statds-36315-spring25/)\"\ndate: 2025-02-12\nengine: knitr\nformat:\n  revealjs:\n    theme: theme.scss\n    chalkboard: true\n    pdf-separate-fragments: true\n    slide-number: c/t\n    smaller: true\n    code-line-numbers: true\n    linestretch: 1.25\n    html-math-method:\n      method: mathjax\n      url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\n---\n\n\n\n\n\n\n## Announcements, previously, and today...\n\n::: {style=\"font-size: 80%;\"}\n\n+ **HW3 is due TONIGHT by 11:59 PM and you have Lab 5 again on Friday!**\n\nOffice hours schedule:\n\n+ My office hours (BH 132D): Wednesdays and Thursdays @ 2 PM\n\n+ Anna (zoom): Mondays @ 2 PM; and Perry (zoom): **Tuesdays** @ 11 AM\n\n:::\n\n. . .\n\n::: {style=\"font-size: 80%;\"}\n\n\nFinished discussed density based visualizations\n\nIntroduced KS test for testing if distribution follows a particular distribution\n\nGraphics are extremely useful because human eyes can quickly compare and contrast distributions...\n\n\n:::\n\n. . .\n\n::: {style=\"font-size: 80%;\"}\n\n**TODAY:**\n\n+ Understanding the statistical power of tests and graphics\n\n:::\n\n---\n\n## Flipper length example\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/kstest-plot-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n---\n\n## Statistical Tests for Comparing Distributions\n\n::: {style=\"font-size: 85%;\"}\n\n+ We've focused on assessing if a single quantitative variable follows a particular distribution\n\n  + Logic of one-sample KS test: Compare empirical distribution to theoretical distribution\n  \n:::\n\n. . .\n\n::: {style=\"font-size: 85%;\"}\n\n**How do we compare multiple empirical distributions?**\n\nVery common scenario: Determine if a quantitative variable depends on a categorical variable, examples:\n  \n+ Clinical trials with multiple treatments\n  \n+ Assessing differences across race, gender, socioeconomic status\n  \n+ Industrial experiments, A/B testing\n  \n+ _Comparing song duration across different genres?_\n    \nCan use overlayed densities, side-by-side violin plots, facetted histograms\n\nRemember: plotting conditional distributions... but when are differences in a graphic _statistically significant_?\n\n:::\n\n---\n\n## [TidyTuesday](https://github.com/rfordatascience/tidytuesday) [Spotify Songs](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md) - Duration by Genre\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n---\n\n## [TidyTuesday](https://github.com/rfordatascience/tidytuesday) [Spotify Songs](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md) - Duration by Genre\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n---\n\n## Test difference between rap and rock?\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n---\n\n## Kolmogorov-Smirnov Test... Again\n\nKS test can also be used to compare two empirical distributions $\\hat{F}_A(x)$ and $\\hat{F}_B$, via test statistic for __two samples__:\n\n$$\n\\text{max}_x |\\hat{F}_A(x) - \\hat{F}_B(x)|\n$$\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nspotify_songs <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv')\nrap_duration <- spotify_songs |> filter(playlist_genre == \"rap\") |> pull(duration_ms)\nrock_duration <- spotify_songs |> filter(playlist_genre == \"rock\") |> pull(duration_ms)\n\nks.test(rap_duration, y = rock_duration)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAsymptotic two-sample Kolmogorov-Smirnov test\n\ndata:  rap_duration and rock_duration\nD = 0.22386, p-value < 2.2e-16\nalternative hypothesis: two-sided\n```\n\n\n:::\n:::\n\n\n\n\n\n\n---\n\n\n## Kolmogorov-Smirnov Test... Again\n\nKS test can also be used to compare two empirical distributions $\\hat{F}_A(x)$ and $\\hat{F}_B$, via test statistic for __two samples__:\n\n$$\n\\text{max}_x |\\hat{F}_A(x) - \\hat{F}_B(x)|\n$$\n\n\n\n\n---\n\n## Statistical Tests for Comparing Distributions\n\n::: {style=\"font-size: 75%;\"}\n\nInfinite number of ways that you can compare multiple quantitative distributions, 3 common ways:\n\n1. __Any difference at all?__ <!--Two sample KS test-->\n\n\n2. __Difference in means?__\n\n  - Null hypothesis: $H_0: \\mu_1 = \\mu_2 = \\cdots = \\mu_K$ (use `t.test` or `oneway.test()` functions)\n  \n  - Can assume the variances are all the same or differ\n  \n  - If reject, can only conclude __not all means are equal__\n  \n3. __Difference in variances?__\n\n  - Null hypothesis: $H_0: \\sigma^2_1 = \\sigma^2_2 = \\cdots = \\sigma^2_K$ (use `bartlett.test()` function)\n  \n  - If reject, can only conclude __not all variances are equal__\n  \nUnlike the KS test, __difference in means and variances are sensitive to non-Normality__\n\n  + Different distributions can yield insignificant results\n\n:::\n\n---\n\n## Test difference between rap and rock?\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n---\n\n## Test difference between rap and rock?\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n---\n\n## Test difference between pop and rap?\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n---\n\n## Recap: One-Sample KS Test\n\n::: {style=\"font-size: 75%;\"}\n\n+ Have a single sample $\\mathbf{X} = (X_1,\\dots,X_n)$\n\n+ Want to test: Does $\\mathbf{X}$ follow a particular distribution?\n\n+ Compares the empirical CDF of $\\mathbf{X}$ to the theoretical CDF of a particular distribution:\n\n$$\\underbrace{F(x) = P(X \\leq x)}_{\\text{theoretical CDF}}, \\hspace{0.2in} \\underbrace{\\hat{F}(x) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{I}(X_i \\leq x)}_{\\text{empirical CDF}}$$\n\n+ Null hypothesis: $\\mathbf{X}$ follows a distribution with CDF $F(x)$\n\n+ Alternative hypothesis: $\\mathbf{X}$ does not follow this distribution\n\n+ Test statistic: $\\max_x |\\hat{F}(x) - F(x)|$\n\n+ If $\\hat{F}(x)$ is far away from $F(x)$ $\\rightarrow$ __reject null__\n\n:::\n\n---\n\n## Recap: Two-Sample KS Test\n\n::: {style=\"font-size: 75%;\"}\n\n+ Have two samples $\\mathbf{X} = (X_1,\\dots,X_m)$, $\\mathbf{Y} = (Y_1,\\dots,Y_n)$\n\n+ Want to test: Do $\\mathbf{X}$ and $\\mathbf{Y}$ follow the same distribution?\n\n+ Compares the empirical CDFs of $\\mathbf{X}$ and $\\mathbf{Y}$:\n\n$$\\underbrace{\\hat{F}_X(z) = \\frac{1}{m} \\sum_{i=1}^m \\mathbb{I}(X_i \\leq z)}_{\\text{empirical CDF of } \\mathbf{X}} \\hspace{0.2in} \\underbrace{\\hat{F}_Y(z) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{I}(Y_i \\leq z)}_{\\text{empirical CDF of } \\mathbf{Y}}$$\n\n+ Null hypothesis: $\\mathbf{X}$ and $\\mathbf{Y}$ follow the same distribution.\n\n+ Alternative hypothesis: $\\mathbf{X}$ and $\\mathbf{Y}$ do not follow the same distribution\n\n+ Test statistic: $\\max_z |\\hat{F}_X(z) - \\hat{F}_Y(z)|$\n\n+ If $\\hat{F}_X$ and $\\hat{F}_Y$ are far away from each other $\\rightarrow$ __reject null__\n\n:::\n\n---\n\n## [TidyTuesday](https://github.com/rfordatascience/tidytuesday) [Spotify Songs](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md) - Duration by Genre\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n---\n\n## What about the difference between pop and rap?\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n---\n\n## What about the difference between pop and rap?\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n---\n\n## Significant difference with large sample size\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nspotify_songs <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv')\ntable(spotify_songs$playlist_genre)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  edm latin   pop   r&b   rap  rock \n 6043  5155  5507  5431  5746  4951 \n```\n\n\n:::\n\n```{.r .cell-code}\nrap_duration <- spotify_songs |> filter(playlist_genre == \"rap\") |> pull(duration_ms)\npop_duration <- spotify_songs |> filter(playlist_genre == \"pop\") |> pull(duration_ms)\n\nks.test(rap_duration, y = pop_duration)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAsymptotic two-sample Kolmogorov-Smirnov test\n\ndata:  rap_duration and pop_duration\nD = 0.14569, p-value < 2.2e-16\nalternative hypothesis: two-sided\n```\n\n\n:::\n:::\n\n\n\n\n\n---\n\n## What happens if we had a smaller sample?\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(2017)\nsample_songs <- spotify_songs |>\n  group_by(playlist_genre) |> \n  slice_sample(n = 100)\n\ntable(sample_songs$playlist_genre)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  edm latin   pop   r&b   rap  rock \n  100   100   100   100   100   100 \n```\n\n\n:::\n\n```{.r .cell-code}\nsample_rap_duration <- sample_songs |> filter(playlist_genre == \"rap\") |> pull(duration_ms)\nsample_pop_duration <- sample_songs |> filter(playlist_genre == \"pop\") |> pull(duration_ms)\n\nks.test(sample_rap_duration, y = sample_pop_duration)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAsymptotic two-sample Kolmogorov-Smirnov test\n\ndata:  sample_rap_duration and sample_pop_duration\nD = 0.16, p-value = 0.1545\nalternative hypothesis: two-sided\n```\n\n\n:::\n:::\n\n\n\n\n\n---\n\n\n## But it still looks different???\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n---\n\n## Test difference between means and variances?\n\nCan test difference in means using `t.test()`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt.test(sample_rap_duration, sample_pop_duration)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  sample_rap_duration and sample_pop_duration\nt = 0.83091, df = 172.78, p-value = 0.4072\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -8766.158 21512.638\nsample estimates:\nmean of x mean of y \n 221645.7  215272.5 \n```\n\n\n:::\n:::\n\n\n\n\n\n---\n\n## Test difference between means and variances?\n\nCan test difference in variances using `bartlett.test()`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbartlett.test(list(sample_rap_duration, sample_pop_duration))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  list(sample_rap_duration, sample_pop_duration)\nBartlett's K-squared = 15.54, df = 1, p-value = 8.08e-05\n```\n\n\n:::\n:::\n\n\n\n\n\n**Rejects at $\\alpha = 0.05$ even with this smaller sample size!**\n\n. . .\n\n+ Why did the KS test say they weren't different when the graph were clearly different? Two possible reasons:\n\n  + The sample size might be too small to detect a difference\n  \n  + The KS test is known to have low power\n\n---\n\n## Statistical power\n  \n__Statistical power__ is key to really understanding graphics - you need to know when you're looking at real effects versus noise\n\nHere are two definitions of power (one in English, one in math):\n\n+ English: The probability that we reject the null hypothesis when the null hypothesis is false.\n  \n+ Math: $P(\\text{p-value} \\leq \\alpha | H_0$ is false)\n  \n<!--\n\n+ Main things that affect statistical power:\n\n  + Bigger differences in the data $\\rightarrow$ more power\n  \n  + Smaller variance/error in differences $\\rightarrow$ more power\n  \n  + Bigger sample size $\\rightarrow$ more power\n  \n  + More appropriate statistical test $\\rightarrow$ more power\n\nAlso remember: Type 1 error is falsely rejecting; Type 2 error is falsely failing to reject\n-->\n\n---\n\n## Toy example for understanding statistical power\n\n::: {style=\"font-size: 85%;\"}\n\nConsider two samples:\n\n$$(X_1,\\dots,X_n) \\sim N(0, 1)$$\n$$(Y_1,\\dots,Y_n) \\sim N(\\delta, 1)$$\n\n\nLet's say we use `t.test(x, y)`\n\nWe'll simulate $\\mathbf{X}$ and $\\mathbf{Y}$ 1000 times for some $n$ and $\\delta > 0$\n\n\nWe'll count the number of times we reject\n\n$$\\text{Power} = P(\\text{p-value} \\leq \\alpha | H_0 \\text{ false}) \\\\\n            = P(\\text{p-value} \\leq \\alpha | \\delta > 0) \\\\\n            \\approx \\frac{\\text{# times reject}}{1000}$$\n            \nWe'll consider $n = 10, 20, \\dots, 1000$ and $\\delta = 0.1$ or $\\delta = 0.25$\n\n:::\n\n---\n\n## Toy example: power of $t$-test\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-19-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n\n---\n\n## Another toy example \n\nConsider two samples:\n\n$$(X_1,\\dots,X_n) \\sim N(0, 1)$$\n$$(Y_1,\\dots,Y_n) \\sim N(0, 1.5)$$\n\n\nLet's consider three ways to test differences:\n\n1. `t.test(x, y)`\n\n2. `bartlett.test(list(x, y))`\n\n3. `ks.test(x,y)`\n\nWe'll simulate $\\mathbf{X}$ and $\\mathbf{Y}$ 1000 times for samples sizes $n = 10, 20, \\dots, 1000$\n\n__What do you think the power curves will look like for these methods?__\n\n---\n\n## Comparison of power for the different tests\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-compare-distr-power_files/figure-revealjs/unnamed-chunk-21-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n---\n\n## Recap and next steps\n\n::: {style=\"font-size: 80%;\"}\n\nGraphics should be paired with statistical analyses to determine if what you see is a _true effect_ versus noise\n\n__Even if there is a true effect, you may have limited power to detect it__ (some effects are easier to detect than others)\n  \n__Remember: Power is the probability you reject when the null is false.__ Things that increase statistical power:\n\n+ Increase sample size\n\n+ Reduce variance/error\n\n+ Increase differences / effects\n\n+ Choose appropriate tests!\n\n:::\n\n. . .\n\n::: {style=\"font-size: 80%;\"}\n\n+ **HW3 is due TONIGHT and you have Lab 5 on Friday**\n\n+ **Next time**: 2D Quantitative Data - Scatterplots and Linear Regression\n\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}