{
  "hash": "6bac42f5e616b906e257637bad618ffc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Demo 13: Visualizations for areal data\"\nformat: html\n---\n\n\n\n\n# Visualizing Areal Data Using Spatial Polygons\n  \nWhat is a polygon? I know this is getting back to elementary school stuff, but in short, a polygon is a shape consisting of a finite number of edges to form an enclosed space. Geographic borders making up regions like countries, states, counties, etc., can be envisioned as very complex polygons.\n\n## Plotting spatial objects with `geom_polygon()`\n  \nIn `ggplot()`, polygons are just another geometry, making it really easy to add geographic shapes (e.g. corresponding to countries, states, counties, etc.) to maps. The following code makes a county-level map of the US by utilizing the `geom_polygon()` function. This function just needs a set of latitude and longitude coordinates and the `group` that each of these coordinates belongs to. Each `group` corresponds to a polygon, and the individual latitude and longitude coordinates (many of which will belong to the same `group`) can be \"connected together\" to make a polygon. For example, for the state of Michigan, there are two groups, because it consists of two different polygons. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggmap)\nus_data <- map_data(\"state\")\ncounty_data <- map_data(\"county\")\n\n#For reference, this is what us_data looks like:\nhead(us_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      <NA>\n2 -87.48493 30.37249     1     2 alabama      <NA>\n3 -87.52503 30.37249     1     3 alabama      <NA>\n4 -87.53076 30.33239     1     4 alabama      <NA>\n5 -87.57087 30.32665     1     5 alabama      <NA>\n6 -87.58806 30.32665     1     6 alabama      <NA>\n```\n\n\n:::\n\n```{.r .cell-code}\nus_county_map <- ggplot() + \n  #this creates all of the counties\n  geom_polygon(aes(long, lat, group = group), fill = \"darkblue\", size = 4, \n               data = county_data) + \n  #this draws outlines for the states\n  geom_polygon(aes(long, lat, group = group), color = 'white', \n               fill = NA, data = us_data) + \n  theme_bw() + theme(axis.text = element_blank(), \n                     axis.title = element_blank())\nus_county_map\n```\n\n::: {.cell-output-display}\n![](13-areal-data_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\n\nIn what follows, we'll demonstrate how you can plot state-specific data (i.e., areal data, where each subject is a state). The workflow generalizes to other regions (e.g., maybe you want to plot country-specific data, county-specific data, etc.)\n\nThe workflow will be as follows:\n\n+ Get state boundaries (i.e., the latitude and longitude information at the state level).\n\n+ Get state-specific data. For example, we will use the `state.x77` dataset in the  `datasets` package, which contains information about each of the 50 United States in the 1970s. (Despite its name, none of the data is from 1977. See `help(state.x77)` for more details.)\n\n+ Match the data from the the second bulletpoint to the data from the first bulletpoint (i.e., connect the state-specific data with the state boundary data).\n\n+ Plot the data.\n\nFirst, let's get the state boundaries. (We actually did this earlier when making our US map above, but we'll do it again here for demonstration.)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  Get state borders from ggmap package and maps\nlibrary(maps)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'maps' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'maps'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:purrr':\n\n    map\n```\n\n\n:::\n\n```{.r .cell-code}\n#?map_data \nstate_borders <- map_data(\"state\") \nhead(state_borders)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      <NA>\n2 -87.48493 30.37249     1     2 alabama      <NA>\n3 -87.52503 30.37249     1     3 alabama      <NA>\n4 -87.53076 30.33239     1     4 alabama      <NA>\n5 -87.57087 30.32665     1     5 alabama      <NA>\n6 -87.58806 30.32665     1     6 alabama      <NA>\n```\n\n\n:::\n:::\n\n\n\n\nNow we'll load the state-specific dataset, `state.x77`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(datasets)\n#Note that the state.x77 dataset looks like this:\nhead(state.x77)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Population Income Illiteracy Life Exp Murder HS Grad Frost   Area\nAlabama          3615   3624        2.1    69.05   15.1    41.3    20  50708\nAlaska            365   6315        1.5    69.31   11.3    66.7   152 566432\nArizona          2212   4530        1.8    70.55    7.8    58.1    15 113417\nArkansas         2110   3378        1.9    70.66   10.1    39.9    65  51945\nCalifornia      21198   5114        1.1    71.71   10.3    62.6    20 156361\nColorado         2541   4884        0.7    72.06    6.8    63.9   166 103766\n```\n\n\n:::\n:::\n\n\n\n\nWe'll need to do a minor amount of data manipulation to match the `state.x77` dataset to the `state_borders` dataset. First, note that `state.x77` technically doesn't have a column with the state names; instead, its `rownames` correspond to the state names. So, first we'll have to create a column with the state names. Second, the names within `state_borders` are all lowercase (see above), so we'll need to take that into account with matching the two datasets as well.\n\nThe following code first grabs the rownames of the `state.x77` table, then converts `state.x77` to a `tibble` named `state_data`, and then adds that column with the state names and makes them lower case:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstate_names <- rownames(state.x77)\nstate_data <- as_tibble(state.x77)\nstate_data <- state_data |>\n  mutate(state = state_names) |>\n  mutate(state = tolower(state))\n```\n:::\n\n\n\n\nNow we can match our two datasets using `left_join()`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  join state_data data to state_borders\nstate_borders <- state_borders |>\n  left_join(state_data, by = c(\"region\" = \"state\"))\n#Note that we now have the information from state_data inside\n#our state_borders dataset:\nhead(state_borders)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       long      lat group order  region subregion Population Income Illiteracy\n1 -87.46201 30.38968     1     1 alabama      <NA>       3615   3624        2.1\n2 -87.48493 30.37249     1     2 alabama      <NA>       3615   3624        2.1\n3 -87.52503 30.37249     1     3 alabama      <NA>       3615   3624        2.1\n4 -87.53076 30.33239     1     4 alabama      <NA>       3615   3624        2.1\n5 -87.57087 30.32665     1     5 alabama      <NA>       3615   3624        2.1\n6 -87.58806 30.32665     1     6 alabama      <NA>       3615   3624        2.1\n  Life Exp Murder HS Grad Frost  Area\n1    69.05   15.1    41.3    20 50708\n2    69.05   15.1    41.3    20 50708\n3    69.05   15.1    41.3    20 50708\n4    69.05   15.1    41.3    20 50708\n5    69.05   15.1    41.3    20 50708\n6    69.05   15.1    41.3    20 50708\n```\n\n\n:::\n:::\n\n\n\n\nFinally, we can make a plot of the state-specific data (in this case we focus on the illteracy rate by state in 1970). To do this, we just specify a `fill` within the `geom_polygon()` function. It's also helpful to use the `scale_fill_gradient2()` function to denote what the colors should be for this `fill` (below, we set the `midpoint` within this function equal to the median of the variable we are plotting, which is common practice).\n\n**Important**: If you do this (set the `midpoint` equal to the median), remember that you are forcing half the regions in your map to have \"high value\" colors and half the regions in your map to have \"low value\" colors. Furthermore, when looking at maps like the ones below, you should always keep the scale in mind. For example, there seems to be a distinction between the southern and northern US: They tend to be different colors. Ultimately, though, this difference corresponds to a 1-2% difference in illiteracy rates; we would need to (ironically) read up on illiteracy rates to better understand if this is a scientifically meaningful difference.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  Make the plot!  \n# Before running the following code, you need to have the `mapproj` package\n# install.packages(\"mapproj\")\n#  (Change the fill variable below as you see fit)\n#  (Change the color gradient as you see fit)\nggplot(state_borders) + \n  geom_polygon(aes(x = long, y = lat, group = group,\n                   fill = Illiteracy), color = \"black\") + \n  scale_fill_gradient2(low = \"darkgreen\", mid = \"lightgrey\", \n                       high = \"darkorchid4\", midpoint = 0.95) +\n  theme_void() +\n  coord_map(\"polyconic\") + \n  labs(\n    title = \"Spatial Distribution of Illiteracy Percent by State\",\n    subtitle = \"Percent of Population in State\",\n    caption = \"U.S. Department of Commerce, Bureau of the Census (1977)\",\n    fill = \"Illiteracy %\"\n  ) + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](13-areal-data_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Use `coord_map()` to specify your map projection\n\nIn the above code, note that we have the line `coord_map(\"polyconic\")`. This specifies a certain kind of map projection for our plot. We can consider other projections. For example, an old-school projection we discussed in lecture was the Mercator projection. The below map is the same map as above, but with the Mercator projection.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(state_borders) + \n  geom_polygon(aes(x = long, y = lat, group = group,\n                   fill = Illiteracy), color = \"black\") + \n  scale_fill_gradient2(low = \"darkgreen\", mid = \"lightgrey\", \n                       high = \"darkorchid4\", midpoint = 0.95) +\n  theme_void() +\n  coord_map(\"mercator\") + \n  labs(\n    title = \"Spatial Distribution of Illiteracy Percent by State\",\n    subtitle = \"Percent of Population in State\",\n    caption = \"U.S. Department of Commerce, Bureau of the Census (1977)\",\n    fill = \"Illiteracy %\"\n  ) + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](13-areal-data_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\nNote that the `coord_map()` function is specifying the coordinates of our map.\n\nUnfortunately, some popular projections (like the Robinson projection and the Winkel Tripel projection) are not readily available. It's a little bit annoying to get these projections working in `R`, but it can be done: See [this tutorial](https://wilkelab.org/practicalgg/articles/Winkel_tripel.html). There isn't one \"right\" projection, but some are better than others.\n\n# Statistical Analyses for Areal Data\n\nIn the illiteracy map above, it seems like there is a higher illiteracy rate in the southern US than in the northern US, but is this difference significant? There are two visual ways that we can assess this: One is with dendrograms (which we have already learned) and another way is with what we call \"visual randomization tests.\"\n\n## Dendrogram of States\n\nIf it seems like outcomes tend to cluster geographically (as in the graph above), then automated clustering techniques like hierarchical clustering should be able to pick up geographic clusters. To put it another way: If techniques like hierarchical clustering identify that certain geographic areas have similar outcomes, then there is a strong case to be made that indeed outcomes are clustering geographically.\n\nTo verify areal graph results with dendrograms, you can follow this workflow:\n\n+ Make an areal graph of outcomes (as we did above for illiteracy rates).\n\n+ Using your eyes, identify geographic regions that appear to have similar outcomes. For example, in the graph above, we can broadly identify two clusters: The south and the north.\n\n+ Run hierarchical clustering on your data. When doing this, use the outcome (in this case, illiteracy rates) to measure the \"distance\" between geographic subjects (in this case, states).\n\n+ Make a dendrogram, and color the leaves of the dendrogram by the geographic regions you identified in the second bulletpoint. If the geographic regions tend to cluster together according to the dendrogram, this suggests that, indeed, outcomes are clustering geographically.\n\nBelow is the code to implement this workflow for the illiteracy example. We already completed the first two bulletpoints above, so now we just need to do the last two bulletpoints (below).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remember that we have to scale our data when creating dendrograms\nillit_scaled <- state_data$Illiteracy / sd(state_data$Illiteracy)\n# distance matrix for our dataset\nillit_dist <- dist(illit_scaled)\n# run hierarchical clustering\nillit_hc <- hclust(illit_dist, method = \"complete\")\n# convert to a dendrogram type object\nillit_dend <- as.dendrogram(illit_hc)\n\n#We'll need the following library to make the dendrogram\n#more graphically pleasing:\nlibrary(dendextend)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n---------------------\nWelcome to dendextend version 1.17.1\nType citation('dendextend') for how to cite the package.\n\nType browseVignettes(package = 'dendextend') for the package vignette.\nThe github page is: https://github.com/talgalili/dendextend/\n\nSuggestions and bug-reports can be submitted at: https://github.com/talgalili/dendextend/issues\nYou may ask questions at stackoverflow, use the r and dendextend tags: \n\t https://stackoverflow.com/questions/tagged/dendextend\n\n\tTo suppress this message use:  suppressPackageStartupMessages(library(dendextend))\n---------------------\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dendextend'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:stats':\n\n    cutree\n```\n\n\n:::\n\n```{.r .cell-code}\n# first, let's change the labels according to the state abbreviations\n# (which is available in the datasets library, which we loaded earlier)\nillit_dend <- set(illit_dend, \"labels\", state.abb, order_value = T)\n\n#We will also color the labels by the region of the state.\ntable(state.region) # this comes from the datasets package hence why we didn't load it\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nstate.region\n    Northeast         South North Central          West \n            9            16            12            13 \n```\n\n\n:::\n\n```{.r .cell-code}\nstat_region_colors <- ifelse(state.region == \"Northeast\", \"darkgreen\",\n                             ifelse(state.region == \"South\", \"purple\",\n                                    ifelse(state.region == \"North Central\", \"orange\",\n                                           \"blue\")))\n#Set the leaf labels according to the above colors:\nillit_dend <- set(illit_dend, \"labels_colors\", stat_region_colors, order_value = T)\n# plot the dendrogram\nplot(illit_dend)\n```\n\n::: {.cell-output-display}\n![](13-areal-data_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\nAs we can see, many of the southern states tend to cluster together. Meanwhile, the other clusters are fairly heterogeneous in terms of regions of the US. Thus, it appears that southern states tend to have more similar illiteracy rates (in this case, higher rates) than other parts of the US.\n\n\n## Visual Randomization Tests\n\nIn the above graph, we want to assess if illiteracy rates tend to depend on geography. So, consider the null hypothesis that illiteracy rates *do not* depend on geography. If the null hypothesis is true, what are the chances that our map just \"happened\" to look like the map above?\n\nTo answer this question, we will use a **visual randomization test**. The workflow for a visual randomization test is as follows:\n\n+ Make an areal graph of outcomes (as we did above for illiteracy rates).\n\n+ Shuffle the outcomes randomly a few times (e.g., 8 times). Make a new areal graph for each of these shuffles. (In short, you're taking the colors of your original graph and just shuffling them around the different geographic regions on the map.)\n\n+ Plot your original map along with all of the \"shuffled\" graphs, and show your graphs to someone else. Tell them that one graph is the \"real graph\" and the rest are \"random graphs.\" Can they tell which graph is the real graph? If so, then the graph we have is \"significantly non-random\" in terms of geography.\n\nBelow is the code to implement this workflow for the illiteracy example. We already completed the first bulletpoint, so now we just need to do the last two bulletpoints (below).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# It'll be helpful to write a function that automatically makes a ggplot for us.\n# This is literally the same code we used to generate the original areal map above, but for any dataset called \"state_data\".\nget_state_map_illit <- function(state_data){\n  plot <- ggplot(state_data) + \n    geom_polygon(aes(x = long, y = lat, group = group,\n                     fill = Illiteracy), color = \"black\") +\n    scale_fill_gradient2(low = \"darkgreen\", mid = \"lightgrey\", \n                         high = \"darkorchid4\", midpoint = 0.95) +\n    theme_void() +\n    coord_map(\"polyconic\")\n  return(plot)\n}\n\n# Now we're going to permute (i.e., \"shuffle\") the outcomes a few times. \n# number of randomizations/permutations/shuffles:\nn_shuffles <- 9\n\n# It's helpful to store ggplot objects in lists in R.\n# We haven't talked much about lists in this class, but they\n# are quite flexible and easy to use.\n# For example, we're going to create an object called plot_list.\n# plot_list[[1]] refers to the first object in the list,\n# plot_list[[2]] refers to the second object in the list,\n# and so on.\nplot_list <- list(length = n_shuffles)\n# Will use a for loop to do this\nfor(i in 1:n_shuffles){\n  #create a \"randomized\" dataset\n  state_borders_rand <- state_borders\n  #shuffle the outcomes\n  state_borders_rand$Illiteracy <- sample(state_borders_rand$Illiteracy)\n  #create the plot and store it\n  plot_list[[i]] = get_state_map_illit(state_borders_rand)\n}\n# Could have also do the following for those that don't like for loops... (even\n# though this is still a for loop but calling compiled code underneath)\n# plot_list <- lapply(1:nshuffles, \n#                     function(i) {\n#                       state_borders_rand <- state_borders\n#                       # shuffle the outcomes\n#                       state_borders_rand$Illiteracy <- sample(state_borders_rand$Illiteracy)\n#                       # Return the plot \n#                       get_state_map_illit(state_borders_rand)\n#                     })\n\n\n# pick a random entry of plot_list to be the \"real\" plot\nplot_list[[sample(1:n_shuffles, size = 1)]] = get_state_map_illit(state_borders)\n\n# Plot all the plots together using the cowplot package:\n# install.packages(\"cowplot\")\nlibrary(cowplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'cowplot' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'cowplot'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:ggmap':\n\n    theme_nothing\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:lubridate':\n\n    stamp\n```\n\n\n:::\n\n```{.r .cell-code}\nplot_grid(plotlist = plot_list, ncol = 3)\n```\n\n::: {.cell-output-display}\n![](13-areal-data_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# library(gridExtra)\n# grid.arrange(plot_list[[1]], plot_list[[2]], plot_list[[3]],\n#              plot_list[[4]], plot_list[[5]], plot_list[[6]],\n#              plot_list[[7]], plot_list[[8]], plot_list[[9]],\n#              nrow = 3)\n```\n:::\n\n\n\n\n\nBecause it's really annoying to have all of the legends displayed together, we can use the `cowplot` package to display a single legend below each of these maps. First, we grab a legend using the `get_legend()` function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Grab the legend for just the first plot, since they are all the same\nmap_legend <- get_legend(plot_list[[1]])\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in get_plot_component(plot, \"guide-box\"): Multiple components found;\nreturning the first one. To return all, use `return_all = TRUE`.\n```\n\n\n:::\n:::\n\n\n\n\nNext, we are going to update our `plot_list` so that the legends are removed from \neach of them. We can do this quickly using the `lapply()` function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlegend_free_plot_list <- \n  lapply(1:length(plot_list),\n         function(i) plot_list[[i]] + theme(legend.position = \"none\"))\n```\n:::\n\n\n\n\nAnd finally, we will now use multiple `plot_grid` function calls to display the shuffled maps next to the legend:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_grid(\n  plot_grid(plotlist = legend_free_plot_list, ncol = 3),\n  map_legend, ncol = 2,\n  # Adjust so the maps are much larger:\n  rel_widths = c(4, 1)\n)\n```\n\n::: {.cell-output-display}\n![](13-areal-data_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\n\nIf you can spot which plot is the real plot (**without having seen it previously!!**), then illiteracy rates are significantly non-random across geography.\n\n# Uniform size with [`statebins`](https://github.com/hrbrmstr/statebins)\n\nAn alternative to state-level choropleths, we can instead make state-level bins using the  [`statebins`](https://github.com/hrbrmstr/statebins) package. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statebins)\n# Need to capitalize the first letter of the state_data data to use for this (or\n# get the abbreviations - that would work as well). We can use the str_to_title\n# function from the stringr package loaded in the tidyverse\nstate_data$new_state <- str_to_title(state_data$state)\nstatebins(state_data = state_data, state_col = \"new_state\",\n          value_col = \"Illiteracy\") +\n  labs(title = \"Spatial Distribution of Illiteracy Percent by State\") +\n  theme_statebins()\n```\n\n::: {.cell-output-display}\n![](13-areal-data_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\nWe can customize this in different ways like other `ggplot` objects:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstatebins(state_data = state_data, state_col = \"new_state\",\n          value_col = \"Illiteracy\",\n          # Use the viridis scale\n          ggplot2_scale_function = viridis::scale_fill_viridis) +\n  labs(title = \"Spatial Distribution of Illiteracy Percent by State\") +\n  # Move legend to right\n  theme_statebins(\"right\")\n```\n\n::: {.cell-output-display}\n![](13-areal-data_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n# Additional resources\n\n+ Check out the [`geofacet` package](https://cran.r-project.org/web/packages/geofacet/vignettes/geofacet.html) for arranging plot panels in a similar way to `statebins` except each bin is a plot!\n\n+ The `sp` package used be a popular package to work with map data, but now it's been replaced by the [`sf` package](https://r-spatial.github.io/sf/index.html)\n\n+ [Tutorial for displaying county level maps](https://socviz.co/maps.html#maps), from the [excellent data viz book](https://socviz.co/index.html#preface) that's free online. Just note that it's syntax for the `statebins` package is out of date.\n\n+ [How to make cartograms](https://r-charts.com/spatial/cartogram-ggplot2/)\n\n+ [Choroplethr](https://arilamstein.com/open-source/) suite of packages\n\n",
    "supporting": [
      "13-areal-data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}